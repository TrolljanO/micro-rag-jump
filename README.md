# Micro-RAG: Sistema de Perguntas e Respostas sobre GestÃ£o de Estoques

[![Version](https://img.shields.io/badge/version-0.1.0-blue.svg)](https://github.com/seu-usuario/micro-rag-jump/releases/tag/v0.1.0)
[![Python](https://img.shields.io/badge/python-3.10+-green.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.115.0-teal.svg)](https://fastapi.tiangolo.com/)
[![License](https://img.shields.io/badge/license-MIT-orange.svg)](LICENSE)

> MicroserviÃ§o RAG (Retrieval-Augmented Generation) que responde perguntas sobre gestÃ£o de estoques com base em 3 documentos tÃ©cnicos, retornando resposta, citaÃ§Ãµes e mÃ©tricas detalhadas.

---

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#-visÃ£o-geral)
- [Arquitetura](#-arquitetura)
- [DecisÃµes TÃ©cnicas](#-decisÃµes-tÃ©cnicas)
- [Contrato da API](#-contrato-da-api)
- [InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [Uso](#-uso)
- [MÃ©tricas e Observabilidade](#-mÃ©tricas-e-observabilidade)
- [LimitaÃ§Ãµes e Trade-offs](#-limitaÃ§Ãµes-e-trade-offs)
- [PrÃ³ximos Passos](#-prÃ³ximos-passos)

---

## ğŸ¯ VisÃ£o Geral

Sistema de perguntas e respostas que implementa RAG para responder questÃµes sobre **gestÃ£o de estoques e logÃ­stica** baseado em 3 documentos PDF acadÃªmicos:

1. **GESTAO_DE_ESTOQUES.pdf** (8 pÃ¡ginas)
2. **CONTROLE DE ESTOQUE.pdf** (48 pÃ¡ginas)
3. **PRÃTICAS DA GESTÃƒO ESTOQUES.pdf** (71 pÃ¡ginas)

### Features Implementadas (v0.1.0)

- âœ… IngestÃ£o e indexaÃ§Ã£o de PDFs (127 pÃ¡ginas â†’ 361 chunks)
- âœ… Vector store FAISS com embeddings
- âœ… Endpoint REST `/ask` com FastAPI
- âœ… Pipeline RAG completo (retrieval + generation)
- âœ… CitaÃ§Ãµes de fontes com trechos dos documentos
- âœ… MÃ©tricas detalhadas (latÃªncia, tokens, custo)
- âœ… GPT-4.1 Nano via OpenRouter

### Performance

| MÃ©trica | Valor MÃ©dio |
|---------|-------------|
| **LatÃªncia Total** | ~5 segundos |
| **LatÃªncia Retrieval** | ~1 segundo |
| **LatÃªncia Generation** | ~4 segundos |
| **Custo por Pergunta** | ~$0.0001 USD |
| **Tokens por Resposta** | ~900 tokens |

---

## ğŸ—ï¸ Arquitetura

### Fluxo do Sistema

```

                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Cliente   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ POST /ask
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FastAPI API                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. ValidaÃ§Ã£o (Pydantic)                                â”‚
â”‚  2. RAG Pipeline                                        â”‚
â”‚     â”œâ”€ Retriever (busca no Ã­ndice FAISS)                â”‚
â”‚     â”œâ”€ Generator (GPT-4.1 Nano)                         â”‚
â”‚     â””â”€ Metrics (cÃ¡lculo de mÃ©tricas)                    â”‚
â”‚  3. Response (answer + citations + metrics)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Vector Index       â”‚   âŸº    â”‚   OpenRouter API     â”‚
â”‚   (FAISS)            â”‚   âŸº    â”‚   (LLM + Embeddings) â”‚
â”‚   - 361 chunks       â”‚   âŸº    â”‚   - GPT-4.1 Nano     â”‚
â”‚   - Embeddings       â”‚         â”‚   - text-emb-3-small â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

### Componentes Principais

1. **IngestÃ£o** (`src/ingestion/`)
   - `loader.py`: Extrai texto dos PDFs usando PyMuPDF
   - `chunker.py`: Divide documentos em chunks com overlap
   - `indexer.py`: Gera embeddings e cria Ã­ndice FAISS

2. **RAG Pipeline** (`src/rag/`)
   - `retriever.py`: Busca chunks relevantes por similaridade
   - `generator.py`: Gera resposta usando LLM + contexto
   - `pipeline.py`: Orquestra retrieval + generation + mÃ©tricas

3. **API** (`src/`)
   - `main.py`: Servidor FastAPI com endpoint `/ask`
   - `schemas/`: Modelos Pydantic (request/response)

---

## ğŸ§  DecisÃµes TÃ©cnicas

### 1. Chunking Strategy

**DecisÃ£o:** Chunk size de **800 caracteres** com **overlap de 100 caracteres**

**Justificativa:**
- **800 caracteres (~200 tokens)**: MantÃ©m contexto suficiente para preservar significado completo de parÃ¡grafos tÃ©cnicos
- **100 caracteres de overlap (12.5%)**: Evita perda de informaÃ§Ãµes em fronteiras de chunks sem aumentar excessivamente o Ã­ndice
- **RecursiveCharacterTextSplitter**: Respeita separadores naturais (parÃ¡grafos, frases, palavras) ao invÃ©s de cortar no meio de sentenÃ§as

**Resultado:** 127 pÃ¡ginas â†’ **361 chunks** (mÃ©dia de ~2.8 chunks/pÃ¡gina)

### 2. Top-K Retrieval

**DecisÃ£o:** Top-K = **3 chunks**

**Justificativa:**
- **Balanceamento contexto/custo**: 3 chunks (~2400 caracteres) fornecem contexto suficiente sem exceder limites de prompt
- **Diversidade de fontes**: Permite recuperar informaÃ§Ãµes de atÃ© 3 documentos diferentes
- **Performance**: Menor latÃªncia de retrieval (~1s) comparado a top-k maior

**Trade-off:** Chunks muito especÃ­ficos podem nÃ£o ser recuperados se houver muitos resultados relevantes

### 3. TÃ©cnica de Busca

**DecisÃ£o:** Busca por **similaridade coseno no espaÃ§o vetorial FAISS**

**Justificativa:**
- **FAISS**: RÃ¡pido, eficiente, ideal para ~400 chunks (nÃ£o requer infraestrutura complexa)
- **Similaridade coseno**: MÃ©trica padrÃ£o para embeddings, funciona bem com `text-embedding-3-small`
- **Sem re-ranking**: Para v0.1.0, busca direta Ã© suficiente; re-ranking pode ser adicionado na v1.0.0

**Alternativas consideradas:**
- ChromaDB: Mais pesado, desnecessÃ¡rio para escala atual
- Elasticsearch: Overkill para 361 documentos

### 4. Modelo de LLM

**DecisÃ£o:** **GPT-4.1 Nano** via OpenRouter

**Justificativa:**
- **Custo**: 80% mais barato que alternativas (Llama 3.1 70B, Claude)
- **Performance em RAG**: 93.25% de acurÃ¡cia em tarefas de RAG
- **LatÃªncia**: < 5s para primeiro token, ideal para aplicaÃ§Ã£o interativa
- **Context window**: 1M tokens (suficiente para o domÃ­nio)

**Custo esperado:**
- Prompt: $0.12 / 1M tokens
- Completion: $0.12 / 1M tokens
- **MÃ©dia por pergunta**: ~$0.0001 USD (900 tokens)

### 5. Embeddings

**DecisÃ£o:** **text-embedding-3-small** (OpenAI)

**Justificativa:**
- **DimensÃ£o**: 1536 dimensÃµes (bom equilÃ­brio qualidade/tamanho)
- **Custo**: ~$0.02 / 1M tokens (indexaÃ§Ã£o completa custou < $0.01)
- **Compatibilidade**: Funciona via OpenRouter com mesma API da OpenAI

---

## ğŸ“¡ Contrato da API

### Endpoint: `POST /ask`

Recebe uma pergunta e retorna resposta gerada, citaÃ§Ãµes das fontes e mÃ©tricas de execuÃ§Ã£o.

#### Request

```

{
"question": "string (3-500 caracteres)"
}

```

**Exemplo:**
```

{
"question": "O que Ã© gestÃ£o de estoques?"
}

```

#### Response (Status 200)

```

{
"answer": "string - Resposta gerada pelo modelo",
"citations": [
{
"source": "string - Nome do arquivo PDF",
"excerpt": "string - Trecho relevante do documento (200 caracteres)",
"chunk_id": "integer - ID do chunk utilizado"
}
],
"metrics": {
"total_latency_ms": "float - LatÃªncia total (ms)",
"retrieval_latency_ms": "float - LatÃªncia do retrieval (ms)",
"generation_latency_ms": "float - LatÃªncia da geraÃ§Ã£o (ms)",
"prompt_tokens": "integer - Tokens do prompt",
"completion_tokens": "integer - Tokens da resposta",
"total_tokens": "integer - Total de tokens",
"estimated_cost_usd": "float - Custo estimado (USD)",
"top_k": "integer - NÃºmero de chunks recuperados",
"context_size": "integer - Tamanho do contexto (caracteres)"
}
}

```

**Exemplo de Resposta:**
```

{
"answer": "GestÃ£o de estoques Ã© responsÃ¡vel pelo planejamento e controle do estoque, desde a matÃ©ria-prima atÃ© o produto acabado entregue aos clientes...",
"citations": [
{
"source": "PRÃTICAS DA GESTÃƒO ESTOQUES.pdf",
"excerpt": "O desafio do gestor de estoques Ã© saber quando ressuprir cada produto e quanto deve manter em estoque...",
"chunk_id": 9
},
{
"source": "GESTAO_DE_ESTOQUES.pdf",
"excerpt": "Ã‰ a atividade da empresa que consiste em armazenar matÃ©rias primas e insumos diversos...",
"chunk_id": 18
}
],
"metrics": {
"total_latency_ms": 5089.34,
"retrieval_latency_ms": 1023.12,
"generation_latency_ms": 4066.22,
"prompt_tokens": 623,
"completion_tokens": 126,
"total_tokens": 749,
"estimated_cost_usd": 0.00009,
"top_k": 3,
"context_size": 2400
}
}

```

#### Response (Status 400 - Bad Request)

```

{
"detail": "string - DescriÃ§Ã£o do erro de validaÃ§Ã£o"
}

```

#### Response (Status 500 - Internal Server Error)

```

{
"detail": "string - DescriÃ§Ã£o do erro interno"
}

```

### Outros Endpoints

#### `GET /` - Health Check BÃ¡sico
Retorna status da API.

#### `GET /health` - Health Check Detalhado
Verifica se o pipeline RAG estÃ¡ carregado e pronto.

#### `GET /docs` - DocumentaÃ§Ã£o Interativa
Interface Swagger UI para testar a API.

---

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos

- Python 3.10 ou superior
- Git
- Conta no OpenRouter (ou OpenAI)

### Passo a Passo

1. **Clone o repositÃ³rio:**

```

git clone https://github.com/seu-usuario/micro-rag-jump.git
cd micro-rag-jump

```

2. **Crie e ative o ambiente virtual:**

```

python -m venv venv
source venv/bin/activate  \# Linux/Mac

# ou

venv\Scripts\activate  \# Windows

```

3. **Instale as dependÃªncias:**

```

pip install -r requirements.txt

```

4. **Configure as variÃ¡veis de ambiente:**

Crie um arquivo `.env` na raiz do projeto:

```


# OpenRouter Configuration

OPENAI_API_KEY=sk-or-v1-sua-chave-aqui
OPENAI_BASE_URL=https://openrouter.ai/api/v1
MODEL_NAME=openai/gpt-4.1-nano
EMBEDDING_MODEL=openai/text-embedding-3-small

# RAG Configuration

CHUNK_SIZE=800
CHUNK_OVERLAP=100
TOP_K=3

# App Configuration

DEBUG=True
LOG_LEVEL=INFO
HOST=0.0.0.0
PORT=8000

```

5. **Execute a ingestÃ£o (apenas uma vez):**

```

python -m src.ingestion.indexer

```

Isso vai:
- Ler os 3 PDFs da pasta `data/`
- Fazer chunking (361 chunks)
- Gerar embeddings
- Criar Ã­ndice FAISS em `vector_index/`

6. **Inicie a API:**

```

uvicorn src.main:app --reload --host 0.0.0.0 --port 8000

```

---

## ğŸ’» Uso

### Testando com cURL

```

curl -X POST "http://localhost:8000/ask" \
-H "Content-Type: application/json" \
-d '{"question": "O que Ã© gestÃ£o de estoques?"}'

```

### Testando com Python

```

import requests

response = requests.post(
"http://localhost:8000/ask",
json={"question": "O que Ã© gestÃ£o de estoques?"}
)

data = response.json()
print(f"Resposta: {data['answer']}")
print(f"CitaÃ§Ãµes: {len(data['citations'])}")
print(f"LatÃªncia: {data['metrics']['total_latency_ms']}ms")

```

### Interface Web

Acesse http://localhost:8000/docs para testar via Swagger UI.

---

## ğŸ“Š MÃ©tricas e Observabilidade

### MÃ©tricas Coletadas por RequisiÃ§Ã£o

1. **LatÃªncias:**
   - `total_latency_ms`: Tempo total da requisiÃ§Ã£o
   - `retrieval_latency_ms`: Tempo de busca no Ã­ndice
   - `generation_latency_ms`: Tempo de geraÃ§Ã£o da resposta

2. **Tokens:**
   - `prompt_tokens`: Tokens enviados ao LLM (contexto + pergunta)
   - `completion_tokens`: Tokens gerados na resposta
   - `total_tokens`: Soma total

3. **Custo:**
   - `estimated_cost_usd`: Custo estimado da requisiÃ§Ã£o

4. **Contexto:**
   - `top_k`: NÃºmero de chunks recuperados
   - `context_size`: Tamanho do contexto em caracteres

### MÃ©tricas para ProduÃ§Ã£o

Para um ambiente de produÃ§Ã£o, recomendo monitorar:

| MÃ©trica | Tipo | Objetivo | Alerta |
|---------|------|----------|--------|
| **P50/P95/P99 LatÃªncia Total** | Performance | < 5s (P95) | > 10s |
| **Taxa de Erros** | Confiabilidade | < 1% | > 5% |
| **Custo por RequisiÃ§Ã£o** | Financeiro | < $0.0002 | > $0.001 |
| **Tokens MÃ©dios** | EficiÃªncia | 800-1000 | > 2000 |
| **Taxa de CitaÃ§Ãµes Vazias** | Qualidade | < 5% | > 20% |
| **Groundedness Score** | Qualidade RAG | > 0.8 | < 0.6 |
| **UtilizaÃ§Ã£o de MemÃ³ria** | Infraestrutura | < 2GB | > 4GB |

**Ferramentas recomendadas:**
- Prometheus + Grafana (mÃ©tricas)
- Langfuse / Langsmith (observabilidade LLM)
- Sentry (errors)

---

## âš ï¸ LimitaÃ§Ãµes e Trade-offs

### LimitaÃ§Ãµes Conhecidas

1. **DomÃ­nio Restrito:**
   - Sistema responde APENAS sobre gestÃ£o de estoques
   - Perguntas fora do domÃ­nio podem gerar respostas genÃ©ricas

2. **Guardrails NÃ£o Implementados (v0.1.0):**
   - Sem proteÃ§Ã£o contra prompt injection
   - Sem bloqueio de conteÃºdo inadequado
   - **SerÃ¡ implementado na v1.0.0**

3. **Escalabilidade:**
   - FAISS in-memory: Limita escala a ~10K documentos
   - Para mais documentos, considerar Pinecone/Weaviate

4. **Idioma:**
   - Documentos em portuguÃªs, modelo treinado primariamente em inglÃªs
   - Pode haver pequenas inconsistÃªncias linguÃ­sticas

### Trade-offs

| DecisÃ£o | BenefÃ­cio | Custo |
|---------|-----------|-------|
| **Top-K = 3** | Menor latÃªncia | Pode perder contexto em queries complexas |
| **Chunk size = 800** | Preserva contexto | Ãndice maior (361 chunks) |
| **GPT-4.1 Nano** | 80% mais barato | Qualidade ligeiramente inferior ao GPT-4 |
| **FAISS local** | Sem dependÃªncias externas | NÃ£o escala alÃ©m de 10K docs |
| **Sem re-ranking** | Menor latÃªncia | PrecisÃ£o pode melhorar com re-ranking |

---

## ğŸ”œ PrÃ³ximos Passos (v1.0.0)

### Funcionalidades

- [ ] **Guardrails:**
  - Bloqueio de prompt injection
  - ValidaÃ§Ã£o de domÃ­nio (rejeitar perguntas sobre CPF, RG, etc)
  - DetecÃ§Ã£o de conteÃºdo inadequado

- [ ] **Melhorias de Qualidade:**
  - Re-ranking com cross-encoder
  - Prompt engineering avanÃ§ado
  - AvaliaÃ§Ã£o automÃ¡tica de groundedness

- [ ] **Testes:**
  - Testes unitÃ¡rios (pytest)
  - Testes de integraÃ§Ã£o
  - Roteiro de validaÃ§Ã£o manual

### Infraestrutura

- [ ] **CI/CD:**
  - GitHub Actions (lint, tests, build)
  - Versionamento de prompts
  - Deploy automatizado

- [ ] **Monitoramento:**
  - Logging estruturado
  - MÃ©tricas Prometheus
  - Dashboards Grafana

### DocumentaÃ§Ã£o

- [ ] Architecture Decision Records (ADRs)
- [ ] Guia de contribuiÃ§Ã£o
- [ ] Exemplos de uso avanÃ§ado

---

## ğŸ“ LicenÃ§a

Este projeto Ã© licenciado sob a MIT License.

---

## ğŸ‘¤ Autor

**Guilherme Trajano**
- GitHub: [@TrolljanO](https://github.com/TrolljanO)
- LinkedIn: [Guilherme Trajano](https://linkedin.com/in/trajanogui)